# 5-Day Gen AI Intensive Course

This repo stores the Kaggle 5-day Generative AI course notebooks

course video recording:
[Youtube livestream recording](https://www.youtube.com/watch?v=kpRyiJUUFxY&list=PLqFaTIg4myu-b1PlxitQdY0UYIbys-2es)


## Day 2
Resources mentioned in today's livestream:
Jinhyuk Lee's Google Scholar [profile](https://scholar.google.com/citations?user=YWm_zVcAAAAJ&hl=en)

The original transformer paper: [Attention Is All You Need](https://arxiv.org/abs/1706.03762)

BERT paper explaining bidirectional attention: [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)

A recent paper from NVidia explaining how to adapt decoder-only language model for embedding generation: [NV-Embed: Improved Techniques for Training LLMs as Generalist Embedding Models](https://arxiv.org/abs/2405.17428)

Whitepaper explaining ["Native Integration of the ScaNN Algorithm into AlloyDB Database Internals"](https://services.google.com/fh/files/misc/scann_for_alloydb_whitepaper.pdf)

Assignments:

➡️ [Optional] Listen to the [summary podcast episode](https://www.youtube.com/watch?v=1CC39K76Nqs&t=0s) for this unit (created by NotebookLM, https://notebooklm.google.com/).

➡️ Read the “Embeddings and Vector Stores/Databases” [whitepaper](https://www.kaggle.com/whitepaper-embeddings-and-vector-stores)

➡️ Complete these code labs on Kaggle:
Build a RAG question-answering system over custom documents 

- [Day 2 - Document Q&A with RAG](https://www.kaggle.com/code/markishere/day-2-document-q-a-with-rag)

Explore text similarity with embeddings 

- [Day 2 - Embeddings and similarity scores](https://www.kaggle.com/code/markishere/day-2-embeddings-and-similarity-scores)

Build a neural classification network with Keras using embeddings 

- [Day 2 - Classifying embeddings with Keras](https://www.kaggle.com/code/markishere/day-2-classifying-embeddings-with-keras)
