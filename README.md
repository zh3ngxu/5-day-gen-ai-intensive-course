# 5-Day Gen AI Intensive Course

This repo stores the Kaggle 5-day Generative AI course notebooks

course video recording:
[Youtube livestream recording](https://www.youtube.com/watch?v=kpRyiJUUFxY&list=PLqFaTIg4myu-b1PlxitQdY0UYIbys-2es)


## Day 1 Foundational Large Language Models & Text Generation
Complete the Intro Unit - “Foundational Large Language Models & Text Generation”, which is:

➡️ [Optional] Listen to the [summary podcast episode](https://www.youtube.com/watch?v=mQDlCZZsOyo&t=0s) for this unit (created by NotebookLM, https://notebooklm.google.com/).

➡️ Read the “Foundational Large Language Models & Text Generation” [whitepaper](https://www.kaggle.com/whitepaper-foundational-llm-and-text-generation)

Complete Unit 1 - “Prompt Engineering”, which is:

➡️ [Optional] Listen to the summary podcast [episode](https://www.youtube.com/watch?v=F_hJ2Ey4BNc) for this unit (created by NotebookLM).

➡️ Read the “Prompt Engineering” [whitepaper](https://www.kaggle.com/whitepaper-prompt-engineering)

➡️ Complete this code lab on Kaggle where you’ll learn prompting fundamentals. Make sure you phone verify (https://www.kaggle.com/settings) your account before starting, it's necessary for the code labs.

[Day 1 - Prompting](https://www.kaggle.com/code/markishere/day-1-prompting)


## Day 2
Resources mentioned in today's livestream:
Jinhyuk Lee's Google Scholar [profile](https://scholar.google.com/citations?user=YWm_zVcAAAAJ&hl=en)

The original transformer paper: [Attention Is All You Need](https://arxiv.org/abs/1706.03762)

BERT paper explaining bidirectional attention: [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)

A recent paper from NVidia explaining how to adapt decoder-only language model for embedding generation: [NV-Embed: Improved Techniques for Training LLMs as Generalist Embedding Models](https://arxiv.org/abs/2405.17428)

Whitepaper explaining ["Native Integration of the ScaNN Algorithm into AlloyDB Database Internals"](https://services.google.com/fh/files/misc/scann_for_alloydb_whitepaper.pdf)

Assignments:

➡️ [Optional] Listen to the [summary podcast episode](https://www.youtube.com/watch?v=1CC39K76Nqs&t=0s) for this unit (created by NotebookLM, https://notebooklm.google.com/).

➡️ Read the “Embeddings and Vector Stores/Databases” [whitepaper](https://www.kaggle.com/whitepaper-embeddings-and-vector-stores)

➡️ Complete these code labs on Kaggle:
Build a RAG question-answering system over custom documents 

- [Day 2 - Document Q&A with RAG](https://www.kaggle.com/code/markishere/day-2-document-q-a-with-rag)

Explore text similarity with embeddings 

- [Day 2 - Embeddings and similarity scores](https://www.kaggle.com/code/markishere/day-2-embeddings-and-similarity-scores)

Build a neural classification network with Keras using embeddings 

- [Day 2 - Classifying embeddings with Keras](https://www.kaggle.com/code/markishere/day-2-classifying-embeddings-with-keras)
